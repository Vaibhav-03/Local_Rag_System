# ğŸ“š Local RAG System - Comprehensive Documentation

> **A Fully Local Retrieval-Augmented Generation System for Laptop-Scale Inference**

---

## ğŸ“‹ Table of Contents

1. [Overview](#1-overview)
2. [System Architecture](#2-system-architecture)
3. [Environment Setup](#3-environment-setup)
4. [CLI Tool Usage](#4-cli-tool-usage)
5. [Usage Examples with Expected Outputs](#5-usage-examples-with-expected-outputs)
6. [Evaluation & Experimental Results](#6-evaluation--experimental-results)
7. [Retrieval Mechanism Deep Dive](#7-retrieval-mechanism-deep-dive)
8. [LLM Integration](#8-llm-integration)
9. [Additional Features](#9-additional-features)
10. [Limitations & Future Directions](#10-limitations--future-directions)
11. [Whiteboard Discussion Topics](#11-whiteboard-discussion-topics)

---

## 1. Overview

### What is this system?

This is a **fully local RAG (Retrieval-Augmented Generation) system** that runs entirely on consumer hardware without requiring cloud APIs or internet connectivity. It combines:

- **Semantic document retrieval** using vector embeddings and FAISS
- **Local LLM inference** using quantized models via llama.cpp
- **Content safety guardrails** with prompt injection protection
- **Interactive CLI** with rich terminal formatting

### Key Differentiators

| Feature | Cloud RAG (OpenAI + Pinecone) | This System |
|---------|-------------------------------|-------------|
| **Privacy** | Data sent to cloud | 100% local |
| **Cost** | Pay per API call | One-time model download |
| **Latency** | Network dependent | 3-5s total |
| **Offline** | âŒ | âœ… |
| **Hardware** | Any | 16GB RAM recommended |

---

## 2. System Architecture

### 2.1 High-Level Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                 LOCAL RAG SYSTEM                                â”‚
â”‚                        Complete Data Flow Architecture                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  USER QUERY  â”‚
                                    â”‚   (string)   â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                               1. GUARDRAILS LAYER                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Content Filter    â”‚  â”‚  Prompt Injection   â”‚  â”‚   Query Validation      â”‚  â”‚
â”‚  â”‚   (blocked topics)  â”‚  â”‚    Detection        â”‚  â”‚   (length, format)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                  â”‚
â”‚  Output: ALLOW / BLOCK / WARN                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚ If ALLOW
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              2. EMBEDDING LAYER                                  â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                     Sentence-Transformers                                   â”‚ â”‚
â”‚  â”‚                     (all-MiniLM-L6-v2)                                     â”‚ â”‚
â”‚  â”‚                                                                            â”‚ â”‚
â”‚  â”‚  "Is Hirschsprung disease mendelian?"  â”€â”€â–¶  [0.12, -0.34, ...]  (384-dim)â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                  â”‚
â”‚  Model Details:                                                                 â”‚
â”‚  â€¢ Size: 80MB                                                                   â”‚
â”‚  â€¢ Speed: ~14,000 sentences/second                                              â”‚
â”‚  â€¢ Normalized for cosine similarity                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                             3. RETRIEVAL LAYER                                   â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Query Embedding  â”‚â”€â”€â–¶   â”‚   FAISS Index      â”‚â”€â”€â–¶   â”‚  Top-K Results   â”‚   â”‚
â”‚  â”‚   (384-dim vector) â”‚      â”‚   (IndexFlatIP)    â”‚      â”‚  (ranked docs)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â”‚                                         â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                              â”‚ Document Store  â”‚                               â”‚
â”‚                              â”‚  (documents.pkl)â”‚                               â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                                                                  â”‚
â”‚  Retrieval Flow:                                                                â”‚
â”‚  1. Encode query â†’ 384-dim vector                                               â”‚
â”‚  2. Inner product similarity search in FAISS                                    â”‚
â”‚  3. Filter by similarity_threshold (default: 0.3)                               â”‚
â”‚  4. Return top_k documents (default: 5)                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           4. CONTEXT ASSEMBLY                                    â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  System Prompt:                                                            â”‚ â”‚
â”‚  â”‚  "You are a helpful AI assistant with access to a knowledge base..."      â”‚ â”‚
â”‚  â”‚                                                                            â”‚ â”‚
â”‚  â”‚  Retrieved Context:                                                        â”‚ â”‚
â”‚  â”‚  [Source: bioasq_passage_20598273] Coding sequence mutations in RET...    â”‚ â”‚
â”‚  â”‚  [Source: bioasq_passage_6650562] Hirschsprung disease genetics...        â”‚ â”‚
â”‚  â”‚                                                                            â”‚ â”‚
â”‚  â”‚  User Question: Is Hirschsprung disease mendelian?                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                  â”‚
â”‚  Prompt Template (TinyLlama/Llama format):                                        â”‚
â”‚  [INST] <<SYS>> {system_prompt} <</SYS>> {context + question} [/INST]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          5. LLM GENERATION LAYER                                 â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    llama.cpp (GGUF Runtime)                                â”‚ â”‚
â”‚  â”‚                                                                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  Quantized Model: tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf              â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Original: 2.2GB FP16 â†’ Quantized: 670MB Q4                      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Context Window: 4096 tokens                                      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ SIMD-optimized CPU inference                                     â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                                                            â”‚ â”‚
â”‚  â”‚  Generation Parameters:                                                    â”‚ â”‚
â”‚  â”‚  â€¢ max_tokens: 512      â€¢ temperature: 0.7                                â”‚ â”‚
â”‚  â”‚  â€¢ top_p: 0.9           â€¢ repeat_penalty: 1.1                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          6. RESPONSE ASSEMBLY                                    â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  RAGResponse:                                                              â”‚ â”‚
â”‚  â”‚  {                                                                         â”‚ â”‚
â”‚  â”‚    "answer": "Hirschsprung disease shows both Mendelian and complex...",  â”‚ â”‚
â”‚  â”‚    "sources": [                                                            â”‚ â”‚
â”‚  â”‚      { "rank": 1, "source": "bioasq_passage_20598273", "score": 0.82 },  â”‚ â”‚
â”‚  â”‚      { "rank": 2, "source": "bioasq_passage_6650562", "score": 0.76 }    â”‚ â”‚
â”‚  â”‚    ],                                                                      â”‚ â”‚
â”‚  â”‚    "retrieval_time": 1.469,                                               â”‚ â”‚
â”‚  â”‚    "generation_time": 20.7,                                               â”‚ â”‚
â”‚  â”‚    "tokens_used": 1247                                                     â”‚ â”‚
â”‚  â”‚  }                                                                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Component Interaction Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           COMPONENT DEPENDENCIES                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚   config.py   â”‚
                                â”‚ (RAGConfig)   â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                            â”‚                            â”‚
           â–¼                            â–¼                            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   llm.py      â”‚           â”‚ embeddings.py â”‚           â”‚ guardrails.py â”‚
   â”‚  (LocalLLM)   â”‚           â”‚(EmbeddingModelâ”‚           â”‚(ContentGuard- â”‚
   â”‚               â”‚           â”‚ DocChunker)   â”‚           â”‚   rails)      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                            â”‚                            â”‚
           â”‚                            â–¼                            â”‚
           â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
           â”‚                   â”‚ retriever.py  â”‚                     â”‚
           â”‚                   â”‚(VectorRetriev-â”‚                     â”‚
           â”‚                   â”‚    er)        â”‚                     â”‚
           â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
           â”‚                            â”‚                            â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚    rag.py     â”‚
                               â”‚ (RAGPipeline) â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚    cli.py     â”‚
                               â”‚  (User CLI)   â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 Data Flow During Indexing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              INDEXING PIPELINE                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  corpus/                                                      models/
    â”‚                                                            â”‚
    â”œâ”€â”€ doc1.txt â”€â”                                              â”œâ”€â”€ faiss_index
    â”œâ”€â”€ doc2.md  â”€â”¼â”€â”€â–¶ DocumentChunker â”€â”€â–¶ EmbeddingModel â”€â”€â–¶    â”‚
    â”œâ”€â”€ doc3.pdf â”€â”˜         â”‚                    â”‚               â””â”€â”€ documents.pkl
                            â”‚                    â”‚
                            â–¼                    â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   Chunks:       â”‚   â”‚   Embeddings:   â”‚
                   â”‚   - chunk_0     â”‚   â”‚   - [0.1, ...]  â”‚
                   â”‚   - chunk_1     â”‚   â”‚   - [0.2, ...]  â”‚
                   â”‚   - chunk_2     â”‚   â”‚   - [0.3, ...]  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Chunking Parameters:
â€¢ chunk_size: 500 characters
â€¢ chunk_overlap: 50 characters (preserves context across boundaries)

Supported File Types:
â€¢ .txt, .md (native)
â€¢ .pdf (via pypdf)
â€¢ .docx (via python-docx)
```

---

## 3. Environment Setup

### 3.1 Automated End-to-End Setup (Recommended)

The system includes a comprehensive setup script that handles everything:

```bash
# Clone the repository
git clone <repository-url>
cd local-rag-system

# Make the setup script executable
chmod +x scripts/setup.sh

# Run the automated setup
./scripts/setup.sh
```

#### What the setup script does:

| Step | Action | Details |
|------|--------|---------|
| 1 | Python check | Verifies Python 3.9+ is installed |
| 2 | Virtual environment | Creates `venv/` directory |
| 3 | Dependencies | Installs all packages from `requirements.txt` |
| 4 | Directories | Creates `corpus/`, `models/`, `tests/` |
| 5 | Model download | Optionally downloads TinyLlama 1.1B (670MB) or Phi-2 2.7B (1.6GB) |
| 6 | Sample corpus | Creates a sample knowledge base document |

### 3.2 Manual Setup Steps

```bash
# 1. Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate  # Linux/macOS
# OR
.\venv\Scripts\activate   # Windows

# 2. Install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# 3. Create necessary directories
mkdir -p corpus models

# 4. Download a model (choose ONE)

# Option A: TinyLlama 1.1B (default, ~670MB, fast)
wget -P models/ https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf

# Option B: Phi-2 2.7B (better quality, ~1.6GB, recommended for 8GB RAM)
wget -P models/ https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf

# Option C: Mistral 7B Instruct (highest quality, ~4.4GB, needs 16GB RAM)
wget -P models/ https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf

# 5. Add your documents to corpus/
cp /path/to/your/documents/*.txt corpus/
cp /path/to/your/documents/*.md corpus/
cp /path/to/your/documents/*.pdf corpus/

# 6. Build the vector index
python main.py index

# 7. Start the system
python main.py --config config.yaml
```

### 3.3 Dependencies Breakdown

```
# requirements.txt explained:

# LLM Backend
llama-cpp-python>=0.2.20      # GGUF model inference

# Embeddings and Vector Search
sentence-transformers>=2.2.2  # Text embeddings
faiss-cpu>=1.7.4              # Vector similarity search

# Text Processing
langchain>=0.1.0              # Document processing utilities
tiktoken>=0.5.1               # Token counting

# CLI and UX
rich>=13.7.0                  # Beautiful terminal output
click>=8.1.7                  # Command-line interface

# Document Processing
pypdf>=3.17.0                 # PDF reading
python-docx>=1.1.0            # DOCX reading

# Evaluation
pytest>=7.4.3                 # Testing
rouge-score>=0.1.2            # Answer quality metrics
```

### 3.4 Hardware Requirements

| Component | Minimum | Recommended | Notes |
|-----------|---------|-------------|-------|
| **CPU** | Intel i5 / M1 | Intel i7+ / M2+ | More cores = faster generation |
| **RAM** | 8GB | 16GB+ | Model loaded fully into RAM |
| **Storage** | 10GB | 20GB | For models + corpus |
| **Python** | 3.9 | 3.10+ | Type hints compatibility |
| **OS** | Linux/macOS | Any | Windows requires extra setup |
---

## 4. CLI Tool Usage

The CLI is built with [Click](https://click.palletsprojects.com/) for command handling and [Rich](https://rich.readthedocs.io/) for beautiful terminal output.

### 4.1 Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLI ARCHITECTURE                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   main.py       â”‚
                        â”‚   Entry Point   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   cli.py        â”‚
                        â”‚   Click Group   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼           â–¼           â–¼           â–¼           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ query   â”‚ â”‚ index   â”‚ â”‚ stats   â”‚ â”‚init-    â”‚ â”‚interactiveâ”‚
    â”‚ command â”‚ â”‚ command â”‚ â”‚ command â”‚ â”‚config   â”‚ â”‚   mode   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Global Options

These options apply to ALL commands:

| Option | Short | Type | Description |
|--------|-------|------|-------------|
| `--config` | `-c` | PATH | Path to YAML config file |
| `--model` | `-m` | PATH | Path to GGUF model file (overrides config) |
| `--corpus` | `-d` | PATH | Path to corpus directory (overrides config) |
| `--verbose` | `-v` | FLAG | Enable verbose output |

```bash
# Examples of global options usage
python main.py --config config-phi2.yaml                    # Use Phi-2 config
python main.py --model models/phi-2.Q4_K_M.gguf            # Override model path
python main.py --corpus /path/to/my/docs                    # Override corpus dir
python main.py -v                                           # Verbose mode
python main.py -c config.yaml -m models/custom.gguf -v      # Combine options
```

### 4.3 Commands Reference

#### 4.3.1 Interactive Mode (Default)

When no command is specified, the CLI enters interactive chat mode.

```bash
python main.py                                # Default config (TinyLlama + BioASQ)
python main.py --config config-phi2.yaml      # Use Phi-2 model
```

**Interactive Mode Flow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INTERACTIVE MODE FLOW                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Start
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Print      â”‚
â”‚ Banner     â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load RAG   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pipeline   â”‚  (Embedding model, LLM, FAISS index)       â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
      â”‚                                                   â”‚
      â–¼                                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚ Wait for   â”‚â”€â”€â”€â”€â–¶â”‚ quit/exit/q    â”‚â”€â”€â”€â”€â–¶ Exit          â”‚
â”‚ User Input â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
      â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ help           â”‚â”€â”€â”€â”€â–¶ Show Help â”€â”€â”€â”¤
      â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
      â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ stats          â”‚â”€â”€â”€â”€â–¶ Show Stats â”€â”€â”¤
      â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
      â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ clear          â”‚â”€â”€â”€â”€â–¶ Clear Screenâ”€â”¤
      â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
      â–¼                                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ Any other  â”‚â”€â”€â”€â”€â–¶â”‚ Query Pipeline â”‚â”€â”€â”€â”€â–¶â”‚ Print    â”‚â”€â”€â”€â”˜
â”‚ text       â”‚     â”‚ (RAG Process)  â”‚     â”‚ Response â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**In-chat Commands:**

| Command | Description |
|---------|-------------|
| `help` | Display available commands and tips |
| `stats` | Show indexed documents count, embedding dimension, guardrails status |
| `clear` | Clear the terminal screen |
| `quit`, `exit`, `q` | Exit the program |

**Example Session:**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   ğŸ” LOCAL RAG SYSTEM ğŸ”                       â•‘
â•‘         Retrieval-Augmented Generation on Your Laptop         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Loading RAG system... (this may take a moment)
âœ“ 40221 documents ready for retrieval

Commands: 'quit' to exit, 'help' for help, 'stats' for statistics

You: Is Hirschsprung disease mendelian?

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ ğŸ’¬ Response                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Hirschsprung disease shows both Mendelian and multifactorial    â”‚
â”‚ inheritance patterns...                                          â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

ğŸ“š Sources
â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Rank â”ƒ Source                     â”ƒ Relevance  â”ƒ
â”¡â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ 1    â”‚ bioasq_passage_20598273    â”‚ 82%        â”‚
â”‚ 2    â”‚ bioasq_passage_6650562     â”‚ 76%        â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â±ï¸  Retrieval: 1469ms | Generation: 20687ms | Total: 22156ms

You: stats

ğŸ“Š Statistics
  Documents indexed: 40221
  Embedding dimension: 384
  Guardrails: enabled

You: quit
Goodbye! ğŸ‘‹
```

---

#### 4.3.2 Query Command

Ask a single question without entering interactive mode.

**Syntax:**
```bash
python main.py query "YOUR QUESTION" [OPTIONS]
```

**Options:**

| Option | Short | Description |
|--------|-------|-------------|
| `--stream` | `-s` | Stream response token-by-token |
| `--json` | | Output response as JSON |

**Examples:**

```bash
# Basic query
python main.py query "Is the protein Papilin secreted?"

# With Phi-2 model
python main.py query "What is Hirschsprung disease?" --config config-phi2.yaml

# Stream output (see tokens as they generate)
python main.py query "Are long non coding RNAs spliced?" --stream

# JSON output (for integration with other tools)
python main.py query "Has Denosumab been approved by FDA?" --json
```

**JSON Output Format:**

```json
{
  "answer": "Yes, Denosumab (Prolia) has been approved by FDA...",
  "sources": [
    {
      "rank": 1,
      "score": 0.823,
      "source": "bioasq_passage_21784067",
      "text_preview": "Denosumab is a fully human monoclonal..."
    }
  ],
  "query": "Has Denosumab been approved by FDA?",
  "timing": {
    "retrieval_ms": 1256,
    "generation_ms": 18542,
    "total_ms": 19798
  },
  "tokens_used": 823
}
```

---

#### 4.3.3 Index Command

Build or rebuild the FAISS vector index from documents.

**Syntax:**
```bash
python main.py index [OPTIONS]
```

**Options:**

| Option | Short | Description |
|--------|-------|-------------|
| `--corpus` | `-d` | Path to corpus directory (overrides default) |

**Examples:**

```bash
# Index documents from default directory (data/bioasq or corpus/)
python main.py index

# Index from custom directory
python main.py index --corpus /path/to/my/documents

# With custom config
python main.py index --config config.yaml
```

**Expected Output:**

```
ğŸ“ Indexing corpus from: /path/to/corpus

Loading embedding model: all-MiniLM-L6-v2
Indexing documents...

âœ… Successfully indexed 156 document chunks!
```

**Supported File Types:**

| Extension | Format |
|-----------|--------|
| `.txt` | Plain text |
| `.md` | Markdown |
| `.pdf` | PDF documents |
| `.docx` | Microsoft Word |

---

#### 4.3.4 Stats Command

Display detailed system statistics.

**Syntax:**
```bash
python main.py stats
```

**Expected Output:**

```
ğŸ“Š System Statistics

           ğŸ“š Retriever            
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ num_documents      â”‚ 40221       â”‚
â”‚ index_type         â”‚ IndexFlatIP â”‚
â”‚ embedding_dim      â”‚ 384         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        ğŸ§® Embedding Model         
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ model_name         â”‚ all-MiniL.. â”‚
â”‚ dimension          â”‚ 384         â”‚
â”‚ device             â”‚ cpu         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         ğŸ¤– Language Model         
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ model_path         â”‚ models/ti.. â”‚
â”‚ context_length     â”‚ 4096        â”‚
â”‚ n_gpu_layers       â”‚ 0           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### 4.3.5 Init-Config Command

Generate a default configuration file.

**Syntax:**
```bash
python main.py init-config [OPTIONS]
```

**Options:**

| Option | Short | Default | Description |
|--------|-------|---------|-------------|
| `--output` | `-o` | `config.yaml` | Output file path |

**Examples:**

```bash
# Generate default config.yaml
python main.py init-config

# Custom output path
python main.py init-config --output my-custom-config.yaml
```

---

### 4.4 Configuration Files

The system supports multiple config files for different models:

| Config File | Model | Use Case |
|-------------|-------|----------|
| (default) | TinyLlama 1.1B | Fast inference, 4GB RAM |
| `config-phi2.yaml` | Phi-2 2.7B | Better quality, 8GB RAM |
| `config-bioasq.yaml` | TinyLlama 1.1B | BioASQ-specific settings |

```bash
# Use TinyLlama (default)
python main.py

# Use Phi-2 for better quality
python main.py --config config-phi2.yaml

# Use BioASQ config
python main.py --config config-bioasq.yaml
```

### 4.5 Error Handling

The CLI provides helpful error messages:

| Error | Cause | Solution |
|-------|-------|----------|
| "Model path not specified" | No model file found | Download a GGUF model to `models/` |
| "Corpus directory not found" | Invalid corpus path | Check path exists |
| "No files found in corpus" | Empty corpus directory | Add text files to index |
| "exceed context window" | Prompt too long | System auto-truncates (fixed) |

### 4.6 Keyboard Shortcuts

| Shortcut | Action |
|----------|--------|
| `Ctrl+C` | Interrupt current operation |
| `Ctrl+D` | Exit interactive mode |
| `â†‘`/`â†“` | Navigate command history (if `readline` enabled) |
| `quit`, `exit`, `q` | Exit the program |

---

## 5. Usage Examples with Expected Outputs

### 5.1 Starting the System

```bash
$ python main.py --config config.yaml

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   ğŸ” LOCAL RAG SYSTEM ğŸ”                       â•‘
â•‘         Retrieval-Augmented Generation on Your Laptop         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Loading RAG system... (this may take a moment)

Initializing RAG pipeline...
Loading embedding model: all-MiniLM-L6-v2
Embedding dimension: 384
Loading existing index from /path/to/models/faiss_index
Loaded 156 documents
Loading model from models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf...
Using 8 CPU threads
Model loaded in 2.34 seconds
RAG pipeline initialized!

âœ“ 156 documents ready for retrieval

Commands: 'quit' to exit, 'help' for help, 'stats' for statistics

You: 
```

### 5.2 Example Query and Response (BioASQ Dataset)

```
You: Is Hirschsprung disease a mendelian or a multifactorial disorder?

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ ğŸ’¬ Response                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Based on the retrieved context, Hirschsprung disease shows both Mendelian  â”‚
â”‚ and multifactorial inheritance patterns depending on the form:              â”‚
â”‚                                                                             â”‚
â”‚ **Mendelian forms**: Coding sequence mutations in genes like RET, GDNF,    â”‚
â”‚ EDNRB, EDN3, and SOX10 are involved in syndromic forms of Hirschsprung     â”‚
â”‚ disease, which follow Mendelian inheritance patterns.                       â”‚
â”‚                                                                             â”‚
â”‚ **Multifactorial forms**: The non-Mendelian inheritance of sporadic        â”‚
â”‚ non-syndromic Hirschsprung disease is complex, with involvement of         â”‚
â”‚ multiple loci demonstrated in a multiplicative model.                       â”‚
â”‚                                                                             â”‚
â”‚ In summary, syndromic forms are Mendelian while sporadic non-syndromic     â”‚
â”‚ cases show complex multifactorial inheritance.                              â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

                        ğŸ“š Sources                         
â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Rank â”ƒ Source                          â”ƒ Relevance  â”ƒ Preview                   â”ƒ
â”¡â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ 1    â”‚ bioasq_passage_20598273         â”‚ 82%        â”‚ Coding sequence mutatio...â”‚
â”‚ 2    â”‚ bioasq_passage_6650562          â”‚ 76%        â”‚ Hirschsprung disease is...â”‚
â”‚ 3    â”‚ bioasq_passage_15829955         â”‚ 71%        â”‚ The genetics of Hirschs...â”‚
â”‚ 4    â”‚ bioasq_passage_15617541         â”‚ 65%        â”‚ Non-syndromic Hirschspr...â”‚
â”‚ 5    â”‚ bioasq_passage_23001136         â”‚ 58%        â”‚ Multiple loci involved ...â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â±ï¸  Retrieval: 1469ms | Generation: 20687ms | Total: 22156ms | Tokens: 1247
```

### 5.3 Single Query JSON Output

```bash
$ python main.py query "Is the protein Papilin secreted?" --json

{
  "answer": "Yes, papilin is a secreted protein. Based on the retrieved passages, papilin is an extracellular matrix glycoprotein that is secreted and plays a role in tissue morphogenesis and cell migration.",
  "sources": [
    {
      "rank": 1,
      "score": 0.8234,
      "source": "bioasq_passage_21784067",
      "text_preview": "Papilin is a secreted extracellular matrix glycoprotein that..."
    },
    {
      "rank": 2,
      "score": 0.7892,
      "source": "bioasq_passage_19297413", 
      "text_preview": "The secreted protein papilin is involved in basement membrane..."
    }
  ],
  "query": "Is the protein Papilin secreted?",
  "refined_query": null,
  "timing": {
    "generation_ms": 18542,
    "retrieval_ms": 1256,
    "total_ms": 19798
  },
  "tokens_used": 823
}
```

### 5.4 Guardrail Blocking Example

```
You: How to hack into systems

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ ğŸ’¬ Response                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ I'm sorry, but I cannot assist with that topic. Please ask about           â”‚
â”‚ something else.                                                              â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

âš ï¸  Query contains blocked topic: hack
```

### 5.5 Statistics Output

```
You: stats

ğŸ“Š Statistics
  Documents indexed: 156
  Embedding dimension: 384
  Guardrails: enabled
```

---

## 6. Evaluation & Experimental Results

### 6.1 BioASQ Benchmark Results

The system was evaluated on the **rag-mini-bioasq** dataset from Hugging Face, a biomedical question-answering benchmark.

#### Dataset Statistics (rag-mini-bioasq from Hugging Face)

| Metric | Value |
|--------|-------|
| Total passages | ~4,700+ |
| Total questions | 100 |
| Questions with ground truth passages | 100 |
| Questions with reference answers | 100 |
| Average passage length | ~300 characters |
| Average relevant passages per question | ~10 |

**Sample Questions from BioASQ:**
- "Is Hirschsprung disease a mendelian or a multifactorial disorder?"
- "List signaling molecules (ligands) that interact with the receptor EGFR?"
- "Is the protein Papilin secreted?"
- "Are long non coding RNAs spliced?"
- "Has Denosumab (Prolia) been approved by FDA?"

#### Model Comparison: TinyLlama vs Phi-2 (100 Questions)

| Metric | TinyLlama 1.1B | Phi-2 2.7B | Improvement |
|--------|---------------|------------|-------------|
| **Precision@5** | 53.3% | 46.9% | - |
| **Recall@5** | 19.0% | 25.3% | **+33%** |
| **MRR** | 0.702 | 0.710 | +1% |
| **Hit Rate** | 79% | 83% | **+5%** |
| **ROUGE-1** | 0.186 | 0.254 | **+37%** |
| **ROUGE-L** | 0.132 | 0.204 | **+55%** |
| **Avg Total Time** | 22.2s | 55.7s | Slower |

#### TinyLlama 1.1B Results

```json
{
  "num_questions": 100,
  "retrieval": {
    "precision_at_k": 0.533,
    "recall_at_k": 0.190,
    "mrr": 0.702,
    "hit_rate": 0.79
  },
  "generation": {
    "rouge_1": 0.186,
    "rouge_l": 0.132
  },
  "timing": {
    "avg_retrieval_ms": 1469,
    "avg_generation_ms": 20687,
    "avg_total_ms": 22156
  }
}
```

#### Phi-2 2.7B Results

```json
{
  "num_questions": 100,
  "retrieval": {
    "precision_at_k": 0.469,
    "recall_at_k": 0.253,
    "mrr": 0.710,
    "hit_rate": 0.83
  },
  "generation": {
    "rouge_1": 0.254,
    "rouge_l": 0.204
  },
  "timing": {
    "avg_retrieval_ms": 1842,
    "avg_generation_ms": 53825,
    "avg_total_ms": 55667
  }
}
```

#### Metrics Explained

| Metric | Description |
|--------|-------------|
| **Precision@5** | % of retrieved docs that are relevant |
| **Recall@5** | % of all relevant docs that were retrieved |
| **MRR** | Mean Reciprocal Rank (how early relevant doc appears) |
| **Hit Rate** | % of queries with â‰¥1 relevant doc retrieved |
| **ROUGE-1** | Word overlap with reference answers |
| **ROUGE-L** | Longest common subsequence similarity |

### 6.2 Retrieval Quality Analysis

```
Retrieval Performance Breakdown:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
                           Hit Rate by Rank
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Rank 1 (Top Result):    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 62%
Rank 2:                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 52%  
Rank 3:                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 45%
Rank 4:                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 38%
Rank 5:                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 32%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### 6.3 Running the Evaluation

```bash
# Setup BioASQ dataset and index
python scripts/setup_bioasq.py

# Run evaluation with TinyLlama (default)
python scripts/evaluate_bioasq.py

# Run evaluation with Phi-2
python scripts/evaluate_bioasq.py --config config-phi2.yaml

# Run evaluation on subset (faster)
python scripts/evaluate_bioasq.py --num-questions 20

# Run with reduced output
python scripts/evaluate_bioasq.py --quiet
```

#### Expected Evaluation Output

```
======================================================================
BioASQ RAG EVALUATION
======================================================================

[1/100] Is Hirschsprung disease a mendelian or a multifactorial disorder?...
  âœ“ P@K: 0.60 | R@K: 0.22 | ROUGE-1: 0.24 | Time: 21.3s
[2/100] List signaling molecules (ligands) that interact with the receptor EGFR?...
  âœ“ P@K: 0.40 | R@K: 0.15 | ROUGE-1: 0.18 | Time: 19.8s
[3/100] Is the protein Papilin secreted?...
  âœ“ P@K: 0.80 | R@K: 0.30 | ROUGE-1: 0.31 | Time: 20.5s
[4/100] Are long non coding RNAs spliced?...
  âœ“ P@K: 0.60 | R@K: 0.25 | ROUGE-1: 0.22 | Time: 21.8s
...
[100/100] Has Denosumab (Prolia) been approved by FDA?...
  âœ“ P@K: 0.80 | R@K: 0.25 | ROUGE-1: 0.21 | Time: 22.1s

======================================================================
EVALUATION SUMMARY
======================================================================

ğŸ“Š Retrieval Metrics (on 100 questions with ground truth):
   Precision@K:  0.533
   Recall@K:     0.190
   MRR:          0.702
   Hit Rate:     79.0%

ğŸ“ Generation Metrics (on 100 questions with answers):
   ROUGE-1:      0.186
   ROUGE-L:      0.132

â±ï¸  Timing:
   Avg Retrieval: 1469ms
   Avg Generation: 20687ms
   Avg Total:     22156ms

======================================================================
Results saved to evaluation_results.json
```

### 6.4 Unit Test Results

```bash
$ pytest tests/ -v

========================= test session starts ==========================
tests/test_rag.py::TestConfig::test_default_config PASSED
tests/test_rag.py::TestConfig::test_config_defaults PASSED
tests/test_rag.py::TestConfig::test_config_yaml_roundtrip PASSED
tests/test_rag.py::TestGuardrails::test_allow_safe_query PASSED
tests/test_rag.py::TestGuardrails::test_block_harmful_query PASSED
tests/test_rag.py::TestGuardrails::test_block_long_query PASSED
tests/test_rag.py::TestGuardrails::test_block_empty_query PASSED
tests/test_rag.py::TestGuardrails::test_block_prompt_injection PASSED
tests/test_rag.py::TestGuardrails::test_sanitize_query PASSED
tests/test_rag.py::TestQueryRefiner::test_detect_ambiguous_query PASSED
tests/test_rag.py::TestQueryRefiner::test_detect_short_query PASSED
tests/test_rag.py::TestQueryRefiner::test_accept_good_query PASSED
tests/test_rag.py::TestDocumentChunker::test_chunk_short_text PASSED
tests/test_rag.py::TestDocumentChunker::test_chunk_long_text PASSED
tests/test_rag.py::TestDocumentChunker::test_chunk_with_metadata PASSED
tests/test_rag.py::TestDocumentChunker::test_chunk_empty_text PASSED
tests/test_rag.py::TestDocument::test_document_creation PASSED
tests/test_rag.py::TestDocument::test_document_serialization PASSED
tests/test_rag.py::TestRetrievalResult::test_format_for_context PASSED
========================= 19 passed in 2.34s ===========================
```

---

## 7. Retrieval Mechanism Deep Dive

### 7.1 Embedding Process

```
                        EMBEDDING PIPELINE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Input Text                    Tokenization               Encoding
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€â”€â”€â”€â”€
"Is papilin secreted?"  â”€â”€â–¶  [is, papilin, ...]  â”€â”€â”€â”€â”€â”€â–¶  SentenceTransformer
                                   â”‚                         â”‚
                                   â–¼                         â–¼
                             Token IDs              Transformer Layers
                            [2054, 2003,                    â”‚
                             14751, 136]                    â”‚
                                                           â–¼
                                                    Mean Pooling
                                                           â”‚
                                                           â–¼
                                                    L2 Normalization
                                                           â”‚
                                                           â–¼
                                                    [0.12, -0.34, 0.56, ...]
                                                    (384 dimensions)
```

#### Model Details: all-MiniLM-L6-v2

| Property | Value |
|----------|-------|
| Architecture | BERT-based transformer |
| Layers | 6 |
| Hidden size | 384 |
| Parameters | 22M |
| Training | Contrastive learning on 1B+ pairs |
| Speed | ~14,000 sentences/sec (CPU) |

### 7.2 FAISS Index Structure

```
                          FAISS IndexFlatIP
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Structure: Flat (brute-force) Inner Product index

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Index Matrix                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Doc 0: [0.12, -0.34, 0.56, ..., 0.08]  (384-d) â”‚   â”‚
â”‚  â”‚ Doc 1: [0.23, 0.45, -0.67, ..., 0.15]  (384-d) â”‚   â”‚
â”‚  â”‚ Doc 2: [-0.18, 0.29, 0.41, ..., -0.22] (384-d) â”‚   â”‚
â”‚  â”‚ ...                                              â”‚   â”‚
â”‚  â”‚ Doc N: [0.09, -0.56, 0.33, ..., 0.44]  (384-d) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                         â”‚
â”‚  Search: query Â· doc = similarity score                 â”‚
â”‚  (Inner product = cosine similarity for normalized vecs)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Why IndexFlatIP?
â€¢ Exact search (no approximation error)
â€¢ Fast for < 1M documents
â€¢ Simple to implement and debug
â€¢ Memory efficient for our scale
```

### 7.3 Retrieval Algorithm

```python
# Simplified retrieval flow (see src/retriever.py for full implementation)

def retrieve(query: str, top_k: int = 5) -> List[RetrievalResult]:
    # Step 1: Encode query
    query_embedding = embedding_model.encode(query)  # Shape: (384,)
    
    # Step 2: FAISS search
    scores, indices = faiss_index.search(
        query_embedding.reshape(1, -1),  # Shape: (1, 384)
        k=top_k
    )
    # scores: [[0.87, 0.72, 0.65, 0.58, 0.45]]
    # indices: [[42, 156, 89, 23, 201]]
    
    # Step 3: Filter by threshold
    results = []
    for score, idx in zip(scores[0], indices[0]):
        if score >= similarity_threshold:  # Default: 0.3
            results.append(RetrievalResult(
                document=documents[idx],
                score=score,
                rank=len(results) + 1
            ))
    
    return results
```

### 7.4 Document Chunking Strategy

The system supports two chunking approaches depending on the data source:

#### BioASQ Dataset (Pre-chunked Passages)

For the BioASQ benchmark dataset, passages are **pre-chunked** from Hugging Face:

```
BioASQ Passage Structure:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Source: rag-datasets/rag-mini-bioasq from Hugging Face

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Passage ID: 20598273                                    â”‚
â”‚  Text: "Coding sequence mutations in RET and EDNRB      â”‚
â”‚         are involved in Hirschsprung disease..."        â”‚
â”‚  Avg Length: ~300 characters                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Dataset Statistics:
â€¢ Total passages: ~4,700+
â€¢ Each passage = 1 indexed document (no additional chunking)
â€¢ Pre-processed for biomedical domain
â€¢ Passage IDs map to ground truth for evaluation
```

#### Custom Documents (Fixed-size Chunking)

For your own documents in `corpus/`, the system uses fixed-size character chunking:

```
                        CHUNKING EXAMPLE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Original Document (1500 chars):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Machine learning is a subset of artificial              â”‚
â”‚ intelligence. It focuses on building systems that       â”‚
â”‚ learn from data. Deep learning is a subset of ML.       â”‚
â”‚ [... more content ...]                                  â”‚
â”‚ Neural networks are inspired by the human brain.        â”‚
â”‚ They consist of layers of interconnected nodes.         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Chunking Parameters (configurable in config.yaml):
â€¢ chunk_size: 500 characters
â€¢ chunk_overlap: 50 characters

Result:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Chunk 0     â”‚ chars 0-500
â”‚ "Machine learn- â”‚
â”‚  ing is a sub-  â”‚
â”‚  set of..."     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 50 char overlap
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Chunk 1     â”‚ chars 450-950
â”‚ "...of ML. Deep â”‚
â”‚  learning is a  â”‚
â”‚  subset of..."  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 50 char overlap
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Chunk 2     â”‚ chars 900-1400
â”‚ "...Neural net- â”‚
â”‚  works are in-  â”‚
â”‚  spired by..."  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Benefits of Overlap:
â€¢ Preserves context at chunk boundaries
â€¢ Prevents splitting important phrases
â€¢ Improves retrieval for queries spanning chunk edges
```

---

## 8. LLM Integration

### 8.1 Quantization Deep Dive

```
                    QUANTIZATION COMPARISON
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Model: TinyLlama 1.1B (1.1 billion parameters) - Current Default

Precision     Memory      Speed     Quality    Selected
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FP32          4.4 GB      1.0x      100%       âŒ Large
FP16          2.2 GB      1.2x      99.9%      Consider
Q8_0          1.2 GB      1.5x      99.5%      Consider
Q5_K_M        850 MB      1.8x      99.0%      Consider
Q4_K_M        670 MB      2.0x      98.5%      âœ… SELECTED
Q4_0          600 MB      2.1x      97.0%      âŒ Quality

Why TinyLlama with Q4_K_M?
â€¢ Extremely lightweight: only 670MB on disk
â€¢ Fast inference even on modest CPUs
â€¢ Good for 8GB RAM systems
â€¢ Trained on 3 trillion tokens for its size
â€¢ Best choice for resource-constrained laptops

Recommended: Phi-2 Q4_K_M (1.6GB)
â€¢ Better quality than TinyLlama
â€¢ Works on 8GB RAM machines
â€¢ Optimal for laptop inference

Alternative: Mistral 7B Q4_K_M (4.4GB)
â€¢ Highest quality
â€¢ Requires 16GB RAM
â€¢ Higher quality responses
â€¢ Requires 16GB+ RAM
â€¢ ~3x slower inference
â€¢ Recommended for production use with sufficient hardware
```

### 8.2 llama.cpp Integration

```
                    LLAMA.CPP ARCHITECTURE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Python Layer                          â”‚
â”‚                 (llama-cpp-python)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ ctypes bindings
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    C++ Layer                             â”‚
â”‚                   (llama.cpp)                            â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    GGML     â”‚  â”‚   Memory    â”‚  â”‚   Inference     â”‚ â”‚
â”‚  â”‚   Tensors   â”‚  â”‚   Mapping   â”‚  â”‚   Engine        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”‚  Optimizations:                                          â”‚
â”‚  â€¢ SIMD (AVX2, AVX-512, ARM NEON)                       â”‚
â”‚  â€¢ Batch processing                                      â”‚
â”‚  â€¢ KV cache for context reuse                           â”‚
â”‚  â€¢ Optional GPU offload (CUDA, Metal, OpenCL)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.3 Prompt Template

```python
# Chat format for TinyLlama/Mistral/Llama instruction-tuned models

def build_prompt(user_query: str, context: str, system_prompt: str) -> str:
    """
    Build prompt in Llama/Mistral instruction format (used by TinyLlama).
    Note: <s> token is added automatically by llama.cpp
    """
    return f"""[INST] <<SYS>>
{system_prompt}
<</SYS>>

Based on the following context, please answer the question.
If the context doesn't contain enough information, say so clearly.

**Context:**
{context}

**Question:** {user_query}

**Answer:** [/INST]"""
```

### 8.4 Generation Parameters

| Parameter | Value | Effect |
|-----------|-------|--------|
| `n_ctx` | 4096 | Context window (prompt + response) |
| `max_tokens` | 512 | Maximum response length |
| `temperature` | 0.7 | Creativity (0=deterministic, 1=random) |
| `top_p` | 0.9 | Nucleus sampling threshold |
| `repeat_penalty` | 1.1 | Reduces repetition |
| `stop_sequences` | `["Human:", "User:"]` | Response terminators |

---

## 9. Additional Features

### 9.1 Content Guardrails

The system includes multi-layer safety features:

```
                        GUARDRAILS PIPELINE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Query Input
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Length Check      â”‚â”€â”€â–¶ Block if > 2000 chars
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Empty Check       â”‚â”€â”€â–¶ Block if empty/whitespace
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prompt Injection   â”‚â”€â”€â–¶ Block patterns like:
â”‚     Detection       â”‚    "ignore previous instructions"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    "you are now a different AI"
           â–¼               "[INST]" embedded in query
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Topic Filter      â”‚â”€â”€â–¶ Block keywords:
â”‚                     â”‚    violence, illegal, hack, etc.
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Domain Check      â”‚â”€â”€â–¶ Optional: restrict to allowed topics
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
      âœ… ALLOW
```

### 9.2 Query Refinement

Detects and handles ambiguous queries:

```python
# Examples of query analysis

"what?"           â†’ "Your question seems incomplete. Could you provide more details?"
"help"            â†’ "I'd be happy to help! What would you like to know?"
"it"              â†’ "Could you clarify what you're referring to?"
"maybe something" â†’ "Let me help clarify - what specific aspect would you like to know?"
```

### 9.3 Source Attribution

Every response includes verifiable sources:

```
Sources Table:
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rank â”‚ Source            â”‚ Relevance â”‚ Preview                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1    â”‚ rag_basics.txt    â”‚ 87%       â”‚ RAG combines retrieval...  â”‚
â”‚ 2    â”‚ ml_concepts.md    â”‚ 72%       â”‚ Machine learning is...     â”‚
â”‚ 3    â”‚ ai_overview.pdf   â”‚ 65%       â”‚ Artificial intelligence... â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.4 Streaming Responses

Real-time token generation for interactive experience:

```python
# Enable streaming mode
python main.py query "Which miRNAs are biomarkers for ovarian cancer?" --stream

# Tokens appear as they're generated:
# The... The following... The following miRNAs... could be used... as biomarkers...
```

### 9.5 Multi-Format Document Support

| Format | Library | Notes |
|--------|---------|-------|
| `.txt` | Built-in | Plain text |
| `.md` | Built-in | Markdown |
| `.pdf` | pypdf | Text extraction |
| `.docx` | python-docx | Word documents |

### 9.6 BioASQ Benchmark Integration

Built-in support for the BioASQ biomedical QA dataset:

```bash
# Setup BioASQ dataset
python scripts/setup_bioasq.py

# Run evaluation
python scripts/evaluate_bioasq.py --num-questions 50
```

---

## Appendix A: Configuration Reference

```yaml
# Complete config.yaml with all options

llm:
  model_path: "models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"
  n_ctx: 4096                    # Context window
  max_tokens: 512                # Max response tokens
  temperature: 0.7               # 0-1, higher = more creative
  top_p: 0.9                     # Nucleus sampling
  n_threads: 0                   # 0 = auto-detect
  n_gpu_layers: 0                # GPU layers (0 = CPU only)
  repeat_penalty: 1.1            # Reduce repetition
  stop_sequences:
    - "Human:"
    - "User:"
    - "\n\n\n"

embedding:
  model_name: "all-MiniLM-L6-v2" # Or "all-mpnet-base-v2"
  device: "cpu"                  # "cpu", "cuda", "mps"
  batch_size: 32                 # Documents per batch
  normalize: true                # L2 normalize embeddings

retriever:
  top_k: 5                       # Documents to retrieve
  similarity_threshold: 0.3     # Minimum relevance score
  chunk_size: 500                # Characters per chunk
  chunk_overlap: 50              # Overlap between chunks
  index_path: "models/faiss_index"
  documents_path: "models/documents.pkl"

guardrails:
  enabled: true
  blocked_topics:
    - "illegal activities"
    - "violence"
    - "hate speech"
    - "malware"
    - "exploit"
    - "hack"
    - "weapon"
    - "drug synthesis"
    - "terrorism"
  allowed_domains: []            # Empty = all allowed
  max_query_length: 2000
  rejection_message: "I'm sorry, but I cannot assist with that topic."

system_prompt: |
  You are a helpful AI assistant with access to a knowledge base.
  When answering questions:
  1. Use the provided context to give accurate, sourced answers
  2. If the context doesn't contain relevant information, say so clearly
  3. Cite your sources by referencing the document chunks provided
  4. Be concise but thorough
  5. If you're uncertain, express that uncertainty

verbose: false
corpus_dir: "corpus"
```

---

## Appendix B: Troubleshooting Guide

### Common Issues and Solutions

| Issue | Cause | Solution |
|-------|-------|----------|
| `Model file not found` | Model not downloaded | Run `./scripts/download_model.sh` |
| `Out of memory` | Model too large | Use TinyLlama or reduce n_ctx |
| `Slow generation` | CPU bottleneck | Enable GPU layers or use smaller model |
| `No documents found` | Empty corpus | Add files to `corpus/` and run `index` |
| `Import errors` | Missing dependencies | `pip install -r requirements.txt` |
| `Low relevance scores` | Poor chunking | Adjust chunk_size/overlap |
| `Garbled output` | Model mismatch | Verify correct GGUF format |

---

*Document Version: 1.0*  
*Last Updated: December 2024*

